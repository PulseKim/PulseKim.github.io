<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Towards Natural Prosthetic Hand Gestures: A Common-Rig and Diffusion Inpainting Pipeline Â· Sunwoo Kim</title>
<meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet href=https://PulseKim.github.io/style.main.min.c34e6915a95f1027dad7b48e5d1ff6e2bbf58b4e72c69d7ec6ac8e7352e961dc.css></head><body class=post-template><div class=site-wrapper><header class=site-header><div class="outer site-nav-main"><div class=inner><nav class=site-nav><div class=site-nav-left><a class=site-nav-logo href=https://PulseKim.github.io/>Sunwoo Kim</a><div class=site-nav-content><ul class=nav role=menu><li class=nav-home role=menuitem><a href=/about/>About</a></li><li class=nav-home role=menuitem><a href=/tags/publications/>Publications</a></li><li class=nav-home role=menuitem><a href=https://github.com/PulseKim/>Github</a></li><li class=nav-home role=menuitem><a href=/files/sunwoocv_241005.pdf>CV</a></li></ul></div></div></nav></div></div></header><main id=site-main class="site-main outer"><div class=inner><article class="post-full post"><header class=post-full-header><section class=post-full-tags><a href=/tags/publications>Publications</a></section><h1 class=post-full-title>Towards Natural Prosthetic Hand Gestures: A Common-Rig and Diffusion Inpainting Pipeline</h1><div class=post-full-byline><section class=post-full-byline-content><ul class=author-list><li class=author-list-item><div class=author-card><div class=author-profile-image><svg viewBox="0 0 24 24"><g fill="none" fill-rule="evenodd"><path d="M3.513 18.998C4.749 15.504 8.082 13 12 13s7.251 2.504 8.487 5.998C18.47 21.442 15.417 23 12 23s-6.47-1.558-8.487-4.002zM12 12c2.21.0 4-2.79 4-5s-1.79-4-4-4-4 1.79-4 4 1.79 5 4 5z" fill="#fff"/></g></svg></div><div class=author-info><div class=author-info><h2>Sunwoo Kim</h2></div></div></div><a href=# class="author-avatar author-profile-image"><svg viewBox="0 0 24 24"><g fill="none" fill-rule="evenodd"><path d="M3.513 18.998C4.749 15.504 8.082 13 12 13s7.251 2.504 8.487 5.998C18.47 21.442 15.417 23 12 23s-6.47-1.558-8.487-4.002zM12 12c2.21.0 4-2.79 4-5s-1.79-4-4-4-4 1.79-4 4 1.79 5 4 5z" fill="#fff"/></g></svg></a></li></ul><section class=post-full-byline-meta><h4 class=author-name>Sunwoo Kim</h4><div class=byline-meta-content><time class=byline-meta-date datetime=2024-126-06>1 June 2024</time>
<span class=byline-reading-time><span class=bull>&bull;</span> 1 min read</span></div></section></section></div></header><figure class=post-full-image><img src=/images/a15.gif alt="Towards Natural Prosthetic Hand Gestures: A Common-Rig and Diffusion Inpainting Pipeline"></figure><section class=post-full-content><div class=post-content><p>IEEE Engineering in Medicine and Biology Society (EMBC) 2024</p><h3 id=authors>Authors</h3><p>Seungyup Ka1, Taemoon Jeong1, Sunwoo Kim3, Sankalp Yamsani2, Joohyung Kim2, Sungjoon Choi1,<br>Korea University1, University of Illinois Urbana-Champaign2, NC Research3</p><h3 id=project-page>Project Page</h3><p><a href=https://kaseungyup.github.io/natural-prosthetic-hand-gestures/>https://kaseungyup.github.io/natural-prosthetic-hand-gestures/</a></p><h3 id=abstract>Abstract</h3><p>Existing works on prosthetic hands focus on increasing dexterity by carrying out functional tasks. Achieving specific hand movements, such as pointing the index finger, are desired but research on generating the hand movement itself has yet to be widely explored. In this work, we propose a pipeline for generating hand motion from body motion via using the Common-Rig, a kinematic rig representation for effective motion representation, and a diffusion-based inpainting method, which has shown strengths in generalization and stability. Common rigging is applied to a motion capture dataset with both body and hands information, and hand motions are generated while conditioned on the body motions of a hand-zeroed test set. The generated results of our proposed method, compared to two baseline methods, attain smaller fingertip positional errors and diversity closer to that of the ground truth. In addition, the generated motions are implemented on a real robotic system with prosthetic hands for evaluation.</p></div></section></article></div></main><aside class="read-next outer"><div class=inner><div class=read-next-feed><article class=read-next-card><header class=read-next-card-header><h3><span>More in</span> <a href=/tags/publications>Publications</a></h3></header><div class=read-next-card-content><ul></ul></div></article><article class="post-card post"><a class=post-card-image-link href=https://PulseKim.github.io/posts/humanconquad/><img class=post-card-image src=/images/PushTasks.gif alt="Human Motion Control of Quadrupedal Robots using Deep Reinforcement Learning"></a><div class=post-card-content><a class=post-card-content-link href=https://PulseKim.github.io/posts/humanconquad/><header class=post-card-header><div class=post-card-primary-tag>Publications</div><h2 class=post-card-title>Human Motion Control of Quadrupedal Robots using Deep Reinforcement Learning</h2></header><section class=post-card-excerpt><p><p>Robotics: Science and Systems, 2022</p></p></section></a><footer class=post-card-meta><ul class=author-list><li class=author-list-item><div class=author-name-tooltip>Sunwoo Kim</div><a href=# class="static-avatar author-profile-image"><svg viewBox="0 0 24 24"><g fill="none" fill-rule="evenodd"><path d="M3.513 18.998C4.749 15.504 8.082 13 12 13s7.251 2.504 8.487 5.998C18.47 21.442 15.417 23 12 23s-6.47-1.558-8.487-4.002zM12 12c2.21.0 4-2.79 4-5s-1.79-4-4-4-4 1.79-4 4 1.79 5 4 5z" fill="#fff"/></g></svg></a></li></ul><div class=post-card-byline-content><span>Sunwoo Kim</span>
<span class=post-card-byline-date><time datetime=2022-123-03>28 March 2022</time>
<span class=bull>&bull;</span> 1 min read</span></div></footer></div></article><article class="post-card post"><a class=post-card-image-link href=https://PulseKim.github.io/posts/bodygesture/><img class=post-card-image src=/images/papers_725s3.jpg alt="Body Gesture Generation for Multimodal Conversational Agents"></a><div class=post-card-content><a class=post-card-content-link href=https://PulseKim.github.io/posts/bodygesture/><header class=post-card-header><div class=post-card-primary-tag>Publications</div><h2 class=post-card-title>Body Gesture Generation for Multimodal Conversational Agents</h2></header><section class=post-card-excerpt><p><p>Siggraph Asia, 2024</p></p></section></a><footer class=post-card-meta><ul class=author-list><li class=author-list-item><div class=author-name-tooltip>Sunwoo Kim</div><a href=# class="static-avatar author-profile-image"><svg viewBox="0 0 24 24"><g fill="none" fill-rule="evenodd"><path d="M3.513 18.998C4.749 15.504 8.082 13 12 13s7.251 2.504 8.487 5.998C18.47 21.442 15.417 23 12 23s-6.47-1.558-8.487-4.002zM12 12c2.21.0 4-2.79 4-5s-1.79-4-4-4-4 1.79-4 4 1.79 5 4 5z" fill="#fff"/></g></svg></a></li></ul><div class=post-card-byline-content><span>Sunwoo Kim</span>
<span class=post-card-byline-date><time datetime=2024-1210-10>1 October 2024</time>
<span class=bull>&bull;</span> 1 min read</span></div></footer></div></article></div></div></aside><footer class="site-footer outer"><div class="site-footer-content inner"><section class=copyright><a href=https://PulseKim.github.io/>Sunwoo Kim</a> &copy; 2024</section><nav class=site-footer-nav><a href=https://PulseKim.github.io/>Latest Posts</a>
<a href=https://github.com/PulseKim target=_blank rel=noopener>Github</a>
<a href=https://jonathanjanssens.com target=_blank rel=noopener style=opacity:.5>Hugo Casper3 by Jonathan Janssens</a></nav></div></footer></div></body></html>